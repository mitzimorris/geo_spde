{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Fit the SPDE Spatial Model to the data\n",
    "\n",
    "This notebook:\n",
    "1. Compiles the SPDE Stan model (`spde_pm25.stan`)\n",
    "2. Loads the preprocessed data from `json_data/stan_data.json`\n",
    "3. Runs MCMC sampling\n",
    "4. Provides basic diagnostics and visualization\n",
    "\n",
    "**Prerequisites**: Run the FEM preprocessing notebook first to generate `json_data/stan_data.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# CmdStanPy for Stan interface\n",
    "from cmdstanpy import CmdStanModel, from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "data_path = Path(\"json_data/stan_data.json\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found at {data_path}. \"\n",
    "        \"Please run the FEM preprocessing notebook first.\"\n",
    "    )\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    stan_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded Stan data with {len(stan_data)} fields\")\n",
    "print(f\"\\nData dimensions:\")\n",
    "print(f\"  Observations: {stan_data['N_obs']}\")\n",
    "print(f\"  Mesh vertices: {stan_data['N_vertices']}\")\n",
    "print(f\"  A matrix non-zeros: {stan_data['A_nnz']}\")\n",
    "print(f\"  Q matrix non-zeros: {stan_data['Q_nnz']}\")\n",
    "print(f\"\\nPrior mean PM2.5: {stan_data['prior_mean']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Stan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Stan model\n",
    "model_path = \"spde_pm25.stan\"\n",
    "\n",
    "if not Path(model_path).exists():\n",
    "    raise FileNotFoundError(f\"Stan model not found at {model_path}\")\n",
    "\n",
    "print(\"Compiling Stan model...\")\n",
    "model = CmdStanModel(stan_file=model_path)\n",
    "print(\"Model compiled successfully!\")\n",
    "\n",
    "# Display model code (first 30 lines)\n",
    "print(\"\\nModel structure (first 30 lines):\")\n",
    "print(\"=\"*60)\n",
    "with open(model_path, 'r') as f:\n",
    "    lines = f.readlines()[:30]\n",
    "    print(''.join(lines))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Sampling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling configuration\n",
    "sampling_config = {\n",
    "    'refresh': 10,  # Print progress every X iterations\n",
    "    'adapt_init_phase': 50,\n",
    "    'adapt_metric_window': 25,\n",
    "    'save_warmup' : True,\n",
    "    'output_dir' : 'tmp',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC Sampling\n",
    "\n",
    "**Note**: This may take several minutes depending on your data size and computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sampler\n",
    "print(\"Starting MCMC sampling...\")\n",
    "print(\"This may take several minutes.\\n\")\n",
    "\n",
    "fit = model.sample(\n",
    "    data=stan_data,\n",
    "    **sampling_config\n",
    ")\n",
    "\n",
    "print(\"\\nSampling completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = fit.summary()\n",
    "summary.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for key parameters\n",
    "# Filter for main parameters (not including the spatial field w)\n",
    "main_params = ['alpha', 'sigma', 'tau']\n",
    "param_summary = summary[summary.index.isin(main_params)]\n",
    "\n",
    "print(\"Parameter estimates:\")\n",
    "print(\"=\"*60)\n",
    "print(param_summary[['Mean', 'StdDev', '5%', '95%', 'ESS_bulk', 'R_hat']].round(2))\n",
    "\n",
    "# Check R_hat values\n",
    "max_rhat = param_summary['R_hat'].max()\n",
    "print(f\"\\nMax R_hat for main parameters: {max_rhat:.3f}\")\n",
    "if max_rhat > 1.01:\n",
    "    print(\"Warning: Some R_hat values > 1.01, indicating potential convergence issues\")\n",
    "else:\n",
    "    print(\"All R_hat values < 1.01, indicating good convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Parameter Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract samples for main parameters\n",
    "draws = fit.draws_pd()\n",
    "\n",
    "# Create trace plots\n",
    "fig, axes = plt.subplots(len(main_params), 2, figsize=(12, 10))\n",
    "fig.suptitle('Parameter Trace Plots and Distributions', fontsize=14)\n",
    "\n",
    "for idx, param in enumerate(main_params):\n",
    "    # Trace plot\n",
    "    ax_trace = axes[idx, 0]\n",
    "    for chain in range(4):\n",
    "        chain_draws = draws[draws['chain__'] == chain+1][param]\n",
    "        ax_trace.plot(chain_draws.values, alpha=0.7, linewidth=0.5)\n",
    "    ax_trace.set_ylabel(param)\n",
    "    ax_trace.set_xlabel('Iteration')\n",
    "    ax_trace.set_title(f'{param} chains')\n",
    "    \n",
    "    # Histogram\n",
    "    ax_hist = axes[idx, 1]\n",
    "    ax_hist.hist(draws[param], bins=50, density=True, alpha=0.7, color='blue')\n",
    "    ax_hist.axvline(draws[param].mean(), color='red', linestyle='--', label='Mean')\n",
    "    ax_hist.axvline(draws[param].median(), color='green', linestyle='--', label='Median')\n",
    "    ax_hist.set_xlabel(param)\n",
    "    ax_hist.set_ylabel('Density')\n",
    "    ax_hist.set_title(f'{param} distribution')\n",
    "    ax_hist.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Predictive Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior predictive samples\n",
    "y_rep_cols = [col for col in draws.columns if col.startswith('y_rep[')]\n",
    "y_rep = draws[y_rep_cols].values\n",
    "\n",
    "# Get observed data\n",
    "y_obs = np.array(stan_data['y'])\n",
    "\n",
    "# Calculate posterior predictive mean and intervals\n",
    "y_rep_mean = y_rep.mean(axis=0)\n",
    "y_rep_lower = np.percentile(y_rep, 5, axis=0)\n",
    "y_rep_upper = np.percentile(y_rep, 95, axis=0)\n",
    "\n",
    "# Plot observed vs predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Observed vs predicted means\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_obs, y_rep_mean, alpha=0.5, s=10)\n",
    "ax1.plot([y_obs.min(), y_obs.max()], [y_obs.min(), y_obs.max()], 'r--', label='1:1 line')\n",
    "ax1.set_xlabel('Observed PM2.5')\n",
    "ax1.set_ylabel('Predicted PM2.5 (mean)')\n",
    "ax1.set_title('Observed vs Predicted')\n",
    "ax1.legend()\n",
    "\n",
    "# Coverage plot\n",
    "ax2 = axes[1]\n",
    "in_interval = (y_obs >= y_rep_lower) & (y_obs <= y_rep_upper)\n",
    "coverage = in_interval.mean() * 100\n",
    "\n",
    "ax2.errorbar(y_obs[::10], y_rep_mean[::10], \n",
    "             yerr=[y_rep_mean[::10] - y_rep_lower[::10], \n",
    "                   y_rep_upper[::10] - y_rep_mean[::10]],\n",
    "             fmt='o', alpha=0.3, markersize=3, elinewidth=0.5)\n",
    "ax2.plot([y_obs.min(), y_obs.max()], [y_obs.min(), y_obs.max()], 'r--')\n",
    "ax2.set_xlabel('Observed PM2.5')\n",
    "ax2.set_ylabel('Predicted PM2.5 (90% CI)')\n",
    "ax2.set_title(f'90% Prediction Intervals\\n(Coverage: {coverage:.1f}%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "residuals = y_obs - y_rep_mean\n",
    "print(f\"Residual statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.3f}\")\n",
    "print(f\"  Std: {residuals.std():.3f}\")\n",
    "print(f\"  RMSE: {np.sqrt((residuals**2).mean()):.3f}\")\n",
    "print(f\"  MAE: {np.abs(residuals).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and Visualize Spatial Field\n",
    "\n",
    "The spatial field `w` at mesh vertices captures the spatial correlation structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior mean of spatial field\n",
    "w_cols = [col for col in draws.columns if col.startswith('w[')]\n",
    "w_samples = draws[w_cols].values\n",
    "w_mean = w_samples.mean(axis=0)\n",
    "w_std = w_samples.std(axis=0)\n",
    "\n",
    "print(f\"Spatial field statistics:\")\n",
    "print(f\"  Number of vertices: {len(w_mean)}\")\n",
    "print(f\"  Mean value: {w_mean.mean():.3f}\")\n",
    "print(f\"  Std of means: {w_mean.std():.3f}\")\n",
    "print(f\"  Range: [{w_mean.min():.3f}, {w_mean.max():.3f}]\")\n",
    "\n",
    "# Plot distribution of spatial field values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Distribution of posterior means\n",
    "axes[0].hist(w_mean, bins=50, density=True, alpha=0.7, color='blue')\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='Zero')\n",
    "axes[0].set_xlabel('Spatial field value')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Distribution of Spatial Field (posterior means)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Uncertainty in spatial field\n",
    "axes[1].hist(w_std, bins=50, density=True, alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Posterior std deviation')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Uncertainty in Spatial Field')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Visualization of Spatial Patterns\n",
    "\n",
    "Visualize the spatial field and residuals overlaid on the geographic locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries for geographic visualization\n",
    "import geopandas as gpd\n",
    "from plotnine import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Load original coordinate data\n",
    "pm25_data = pd.read_csv('north_america_pm25.csv')\n",
    "\n",
    "# We need to reload the preprocessed coordinate data\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from geo_spde.coords import preprocess_coords\n",
    "\n",
    "# Get coordinates in original lon/lat\n",
    "lon_lat_coords = pm25_data[['Longitude', 'Latitude']].to_numpy()\n",
    "\n",
    "# Process to get the same cleaned coordinates used in modeling\n",
    "clean_coords, indices, proj_info = preprocess_coords(\n",
    "    lon_lat_coords,\n",
    "    remove_duplicates=True\n",
    ")\n",
    "\n",
    "# Get the cleaned data\n",
    "pm25_clean = pm25_data.iloc[indices].copy()\n",
    "lon_lat_clean = lon_lat_coords[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial field at observation locations using A matrix\n",
    "# Extract A matrix structure from stan_data\n",
    "A_w = np.array(stan_data['A_w'])\n",
    "A_v = np.array(stan_data['A_v']) - 1  # Convert to 0-indexed\n",
    "A_u = np.array(stan_data['A_u']) - 1  # Convert to 0-indexed\n",
    "\n",
    "# Function to multiply sparse CSR matrix with vector\n",
    "def csr_matvec(w_vals, v_indices, u_pointers, x):\n",
    "    \"\"\"Multiply CSR matrix with vector\"\"\"\n",
    "    n_rows = len(u_pointers) - 1\n",
    "    result = np.zeros(n_rows)\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        for j in range(u_pointers[i], u_pointers[i+1]):\n",
    "            result[i] += w_vals[j] * x[v_indices[j]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Compute spatial field at observation locations\n",
    "w_at_obs = csr_matvec(A_w, A_v, A_u, w_mean)\n",
    "\n",
    "# Compute model predictions and residuals\n",
    "alpha_mean = draws['alpha'].mean()\n",
    "\n",
    "# Fixed effects prediction (without spatial field)\n",
    "fixed_pred = alpha_mean\n",
    "\n",
    "# Full model prediction at observations\n",
    "y_pred_full = fixed_pred + w_at_obs\n",
    "\n",
    "# Residuals\n",
    "residuals = y_obs - y_pred_full\n",
    "\n",
    "print(f\"Spatial field contribution at observations:\")\n",
    "print(f\"  Mean: {w_at_obs.mean():.3f}\")\n",
    "print(f\"  Std: {w_at_obs.std():.3f}\")\n",
    "print(f\"  Range: [{w_at_obs.min():.3f}, {w_at_obs.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load USA map from naturalearth\n",
    "url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "world = gpd.read_file(url)\n",
    "north_america_map = world[world['ISO_A3'].isin(['CAN', 'USA', 'MEX'])]\n",
    "\n",
    "# Project map to same coordinate system as our data\n",
    "north_america_proj = north_america_map.to_crs(proj_info['proj4_string'])\n",
    "\n",
    "# Create dataframe with all visualization data\n",
    "viz_df = pd.DataFrame({\n",
    "    'Longitude': lon_lat_clean[:, 0],\n",
    "    'Latitude': lon_lat_clean[:, 1],\n",
    "    'x_proj': clean_coords[:, 0],\n",
    "    'y_proj': clean_coords[:, 1],\n",
    "    'PM25_observed': y_obs,\n",
    "    'PM25_predicted': y_pred_full,\n",
    "    'spatial_field': w_at_obs,\n",
    "    'residual': residuals,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization: Urban vs Rural effects\n",
    "# First, create a proper categorical variable for urban/rural\n",
    "\n",
    "p_map = (ggplot() +\n",
    "    geom_map(north_america_proj, fill='white', color='black', size=0.2) +\n",
    "    geom_point(data=viz_df,\n",
    "               mapping=aes(x='x_proj', y='y_proj', \n",
    "                          color='spatial_field'),\n",
    "               size=0.5, alpha=0.8) +\n",
    "    scale_color_gradient2(low='blue', mid='white', high='red',\n",
    "                          midpoint=0, name='Spatial\\nField') +\n",
    "    theme_minimal() +\n",
    "    labs(title=\"Spatial Field\") +\n",
    "    coord_fixed())\n",
    "display(p_map)\n",
    "\n",
    "# Alternative: Show residuals by urban/rural\n",
    "p_map_residuals = (ggplot() +\n",
    "    geom_map(north_america_proj, fill='white', color='black', size=0.2) +\n",
    "    geom_point(data=viz_df,\n",
    "               mapping=aes(x='x_proj', y='y_proj', \n",
    "                          color='residual'),\n",
    "               size=0.5, alpha=0.8) +\n",
    "    scale_color_gradient2(low='blue', mid='white', high='red',\n",
    "                          midpoint=0, name='Residual\\n(μg/m³)') +\n",
    "    theme_minimal() +\n",
    "    labs(title=\"Model Residuals\") +\n",
    "    coord_fixed())\n",
    "\n",
    "display(p_map_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This notebook successfully:\n",
    "1. Compiled the SPDE Stan model\n",
    "2. Loaded preprocessed data from the FEM pipeline\n",
    "3. Ran MCMC sampling with diagnostics\n",
    "4. Visualized parameter distributions and convergence\n",
    "5. Performed posterior predictive checks\n",
    "6. Extracted and analyzed the spatial field\n",
    "\n",
    "The model captures spatial correlation through the latent field `w`, providing better predictions than a non-spatial model would."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
